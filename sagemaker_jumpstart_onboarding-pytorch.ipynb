{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart 모델 온보딩 (Pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ML 모델 패키징 프로세스\n",
    "\n",
    "<img src=\"images/ml-model-publishing-workflow.png\"/>\n",
    "\n",
    "다음 다이어그램은 ML 모델 패키징 프로세스의 개요를 제공합니다.\n",
    "\n",
    "- **1단계** 모델 아티팩트 및 서빙/스코어링 로직 저장\n",
    "- **2단계** 추론을 수행하는 SageMaker에서 모델을 호스팅하는 데 사용되는 컨테이너를 생성하고 ECR에 푸시\n",
    "- **3단계** SageMaker에서 모델을 성공적으로 호스팅할 수 있는 컨테이너 검증\n",
    "- **4단계** ML 모델을 모델 패키지로 패키징\n",
    "- **5단계** Amazon SageMaker에 배포하여 ML 모델 패키지 검증\n",
    "- **6단계** AWS Marketplace에 ML 모델 등록\n",
    "\n",
    "> **참고**: 모든 로컬 작업은 최적의 성능과 호환성을 위해 반드시 GPU가 지원되는 SageMaker Notebook 인스턴스에서 수행되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo service docker restart\n",
    "    echo \"Docker Restart\"\n",
    "fi\n",
    "\n",
    "sudo curl -L \"https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U sagemaker --quiet\n",
    "    !{sys.executable} -m pip install -U transformers --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "os.environ['HF_HOME'] = '/home/ec2-user/SageMaker/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# model_name_or_path='Salesforce/blip2-opt-2.7b'\n",
    "model_name_or_path='Salesforce/blip-image-captioning-large'\n",
    "cache_dir = f'{Path.cwd()}/cache_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jinja2\n",
    "jinja_env = jinja2.Environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 1**] 모델 아티팩트 및 서빙/스코어링 로직 저장\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_model(hf_model_id, local_model_path, ignore_patterns=None):\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    from huggingface_hub import snapshot_download\n",
    "\n",
    "    # 기본적으로 무시할 패턴 설정 (safetensors는 반드시 포함해야 함)\n",
    "    if ignore_patterns is None:\n",
    "        ignore_patterns = [\"*.ckpt\"]  # 큰 체크포인트 파일만 무시\n",
    "    \n",
    "    local_model_path = Path(local_model_path)\n",
    "    print(f\"Downloading model to: {local_model_path}\")\n",
    "    \n",
    "    # 디렉토리 준비\n",
    "    if os.path.exists(local_model_path):\n",
    "        print(f\"Model directory already exists. Updating files at: {local_model_path}\")\n",
    "    else:\n",
    "        os.makedirs(local_model_path, exist_ok=True)\n",
    "        print(f\"Created new model directory: {local_model_path}\")\n",
    "    \n",
    "    try:\n",
    "        # 모델 다운로드\n",
    "        allow_patterns = [\"*.json\", \"*.safetensors\", \"*.pt\", \"*.txt\", \"*.model\", \"*.tiktoken\", \"*.gguf\"]\n",
    "        \n",
    "        snapshot_download(\n",
    "            repo_id=hf_model_id,\n",
    "            local_dir=local_model_path,\n",
    "            local_dir_use_symlinks=False,\n",
    "            ignore_patterns=ignore_patterns,\n",
    "            allow_patterns=allow_patterns,\n",
    "        )\n",
    "        \n",
    "        # 다운로드 검증\n",
    "        model_files = os.listdir(local_model_path)\n",
    "        print(f\"Downloaded files: {model_files}\")\n",
    "        \n",
    "        # 필수 파일 확인\n",
    "        if not os.path.exists(os.path.join(local_model_path, \"config.json\")):\n",
    "            raise FileNotFoundError(\"config.json이 다운로드되지 않았습니다!\")\n",
    "        \n",
    "        # 가중치 파일 확인\n",
    "        weight_found = False\n",
    "        for file in model_files:\n",
    "            if file.endswith('.bin') or file.endswith('.safetensors'):\n",
    "                weight_found = True\n",
    "                break\n",
    "                \n",
    "        if not weight_found:\n",
    "            raise FileNotFoundError(\"모델 가중치 파일이 다운로드되지 않았습니다!\")\n",
    "            \n",
    "        print(f\"모델 다운로드 완료: {hf_model_id}\")\n",
    "        return local_model_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"모델 다운로드 오류: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf serve/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_model(model_name_or_path, f\"serve/checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀은 src 디렉토리에 SageMaker 추론 스크립트를 저장합니다.\n",
    "\n",
    "#### Option 1.\n",
    "- `model_fn(model_dir)`: S3의 `model_dir`에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `input_fn(request_body, content_type)`: 입력 데이터를 전처리합니다. `content_type`은 입력 데이터 종류에 따라 다양하게 처리 가능합니다. (예: `application/x-npy`, `application/json`, `application/csv`등)\n",
    "- `predict_fn(input_object, model)`: `input_fn(...)`을 통해 들어온 데이터에 대해 추론을 수행합니다.\n",
    "- `output_fn(prediction, accept_type)`: `predict_fn(...)`에서 받은 추론 결과를 후처리를 거쳐 프론트엔드로 전송합니다.\n",
    "\n",
    "#### Option 2.\n",
    "- `model_fn(model_dir)`: S3의 model_dir에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `transform_fn(model, request_body, content_type, accept_type)`: `input_fn(...), predict_fn(...), output_fn(...)`을 `transform_fn(...)`으로 통합할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile serve/inference.py\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from PIL import Image\n",
    "import transformers\n",
    "\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "\n",
    "from sagemaker_inference import encoder\n",
    "\n",
    "data_type = torch.float16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def decode_image(request_body):\n",
    "    buff = BytesIO(base64.b64decode(request_body))\n",
    "    image = Image.open(buff)\n",
    "    return image\n",
    "\n",
    "\n",
    "def _validate_payload(payload: Dict[str, Any]) -> None:\n",
    "    \"\"\"Validate the parameters in the input loads.\n",
    "\n",
    "    Checks if image exists.\n",
    "    Args:\n",
    "        payload: a decoded input payload (dictionary of input parameter and values)\n",
    "    \"\"\"\n",
    "\n",
    "    for param_name in payload:\n",
    "        if param_name not in ['input_image']:\n",
    "            raise KeyError(\n",
    "                f\"Input payload contains an invalid key input_image.\"\n",
    "            ) \n",
    "\n",
    "\n",
    "def model_fn(model_dir: str) -> transformers:\n",
    "    \n",
    "    print(f\"************ model_dir : {model_dir}\")\n",
    "    \n",
    "    model = transformers.BlipForConditionalGeneration.from_pretrained(\n",
    "        f'{model_dir}/checkpoint/',\n",
    "        torch_dtype=data_type\n",
    "    ).to(f\"{device}:0\")\n",
    "    model.eval()\n",
    "    \n",
    "    # model2 = transformers.BlipForConditionalGeneration.from_pretrained(\n",
    "    #     f'{model_dir}/code/checkpoint',\n",
    "    #     torch_dtype=data_type\n",
    "    # ).to(f\"{device}:3\")\n",
    "    model.eval()\n",
    "\n",
    "    processor = transformers.AutoProcessor.from_pretrained(\n",
    "        f'{model_dir}/checkpoint/'\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return (model, processor)\n",
    "\n",
    "\n",
    "def transform_fn(model_return: transformers, payload: bytes, content_type: str, accept: str) -> str:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model, processor = model_return\n",
    "    \n",
    "    if content_type == \"application/x-image\":\n",
    "        try:\n",
    "            payload=decode_image(payload)\n",
    "            inputs = processor(payload, return_tensors=\"pt\").to((f\"{device}:0\"), data_type)\n",
    "        except Exception:\n",
    "            logging.exception(\n",
    "                f\"Failed to parse input payload. For content_type=application/x-image, input \"\n",
    "                f\"payload must be a bytearray encoded image.\"\n",
    "            )\n",
    "            torch.cuda.empty_cache()\n",
    "            raise\n",
    "    elif content_type == \"application/json\":\n",
    "        try:\n",
    "            payload = json.loads(payload)\n",
    "            _validate_payload(payload)\n",
    "            payload=decode_image(payload['input_image'])\n",
    "            inputs = processor(payload, return_tensors=\"pt\").to((f\"{device}:0\"), data_type)\n",
    "        except Exception:\n",
    "            logging.exception(\n",
    "                f\"Failed to parse input payload. For content_type=application/json, input \"\n",
    "                f\"payload must be a json encoded dictionary with keys input_image.\"\n",
    "            )\n",
    "            raise\n",
    "    else:\n",
    "        raise ValueError('{{\"error\": \"unsupported content type {}\"}}'.format(content_type or \"unknown\"))\n",
    "\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        out = model.generate(**inputs)\n",
    "        caption_texts = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        output = {\n",
    "            \"generated_caption\" : caption_texts\n",
    "        }\n",
    "        torch.cuda.empty_cache()\n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        logging.error(\n",
    "            \"Model ran out of CUDA memory while generating images. Please reduce height and width or \"\n",
    "            f\"deploy the model on an instance type with more GPU memory. Error: {e}.\"\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    except Exception:\n",
    "        logging.exception(\"Failed to caption images.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    return encoder.encode(output, accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 2**] 추론 수행을 위한 SageMaker 컨테이너 생성 및 ECR 등록\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    image_scope='inference',\n",
    "    version='2.0',\n",
    "    instance_type='ml.g5.12xlarge'\n",
    ")\n",
    "docker_account_id = image_uri.split('.')[0]\n",
    "print(f'image_uri: {image_uri} \\ndocker_account_id : {docker_account_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf docker && mkdir docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.0-gpu-py310\n",
    "\n",
    "ENV TZ=Asia/Seoul\n",
    "RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n",
    "\n",
    "RUN pip install --no-cache-dir numpy==1.24.3\n",
    "\n",
    "RUN pip install -U --no-cache-dir pip \\\n",
    "    easyocr \\ \n",
    "    simplejpeg \\\n",
    "    Pillow\n",
    "\n",
    "RUN pip install --no-cache-dir pytorch-lightning==2.0.1.post0 \\\n",
    "    git+https://github.com/openai/CLIP.git \\\n",
    "    git+https://github.com/fbcotter/pytorch_wavelets.git \\\n",
    "    git+https://github.com/richzhang/PerceptualSimilarity.git\n",
    "\n",
    "RUN pip install --no-deps open_clip_torch==2.20.0\n",
    "RUN pip install --no-cache-dir transformers==4.32.0 safetensors\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV LANG C.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf shell && mkdir shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile shell/build_and_push.sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name={{algorithm_name}}\n",
    "image_tag={{image_tag}}\n",
    "\n",
    "cd {{root_dir}}/docker\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:${image_tag}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin \"{{docker_account_id}}.dkr.ecr.${region}.amazonaws.com\"\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -f Dockerfile -t ${fullname} .\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithm_name='js-on-boarding-customer'\n",
    "image_tag='blip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = jinja_env.from_string(Path(\"shell/build_and_push.sh\").open().read())\n",
    "Path(\"shell/build_and_push.sh\").open(\"w\").write(template.render(algorithm_name=algorithm_name, image_tag=image_tag, root_dir=os.getcwd(), docker_account_id=docker_account_id))\n",
    "# !pygmentize shell/build_and_push.sh | cat -n\n",
    "!chmod +x shell/build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ./shell/build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "account = sagemaker.Session().account_id()\n",
    "region = sagemaker.Session().boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecr_image_uri=f\"{account}.dkr.ecr.{region}.amazonaws.com/{algorithm_name}:{image_tag}\"\n",
    "ecr_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 3**] SageMaker에서 모델을 성공적으로 호스팅할 수 있는 컨테이너 검증\n",
    "---\n",
    "\n",
    "SageMaker 호스팅 엔드포인트로 배포하기 전에 로컬 모드 엔드포인트로 배포할 수 있습니다. 로컬 모드는 현재 개발 중인 환경에서 도커 컨테이너를 실행하여 SageMaker 프로세싱/훈련/추론 작업을 에뮬레이트할 수 있습니다. 추론 작업의 경우는 Amazon ECR의 딥러닝 프레임워크 기반 추론 컨테이너를 로컬로 가져오고(docker pull) 컨테이너를 실행하여(docker run) 모델 서버를 시작합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Model Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket=sagemaker_session.default_bucket()\n",
    "prefix='blip-large/model_data_customers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo rm -rf serve/.ipynb_checkpoints/\n",
    "!sudo rm -rf serve/__pycache__/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_root_path = Path(\"./serve\")\n",
    "model_upload_paths = {}\n",
    "\n",
    "tar_name = \"model.tar.gz\"\n",
    "\n",
    "!tar -C $model_root_path -czvf $tar_name checkpoint inference.py\n",
    "sagemaker_session.upload_data(path=tar_name, bucket=bucket, key_prefix=prefix)\n",
    "!sudo rm -rf ./model && mkdir ./model\n",
    "!mv $tar_name ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data_url = f's3://{bucket}/{prefix}/{tar_name}'\n",
    "model_data_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker Endpoint (Local Mode)\n",
    "\n",
    "로컬 모드는 필수로 수행할 필요는 없지만, 디버깅에 많은 도움이 됩니다. 또한, 로컬 모드 사용 시에는 모델을 S3에 반드시 업로드할 필요 없이 로컬 디렉터리에서도 로드할 수 있습니다. (`container` 변수 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set to True to enable SageMaker to run locally\n",
    "local_mode = True\n",
    "# local_mode = False\n",
    "if local_mode:\n",
    "    from sagemaker.local import LocalSession\n",
    "    instance_type = \"local_gpu\"\n",
    "    sm_session = LocalSession()\n",
    "    sm_session.config = {'local': {'local_code': True}}\n",
    "    sm_client = sagemaker.local.LocalSagemakerClient()\n",
    "    smr_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    model_data=f\"file://{Path.cwd()}/model/model.tar.gz\"\n",
    "else:\n",
    "    instance_type = \"ml.g5.2xlarge\"\n",
    "    sm_session = sagemaker.Session()\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "    model_data = model_data_url\n",
    "\n",
    "instance_count = 1\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = f\"blip-model-{ts}\"\n",
    "endpoint_config_name = f\"blip-endpoint-config-{ts}\"\n",
    "endpoint_name = f\"blip-endpoint-{ts}\"\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    \"SAGEMAKER_CONTAINER_LOG_LEVEL\" : \"20\",\n",
    "    \"SAGEMAKER_PROGRAM\" : \"inference.py\",\n",
    "    \"SAGEMAKER_REGION\" : \"us-west-2\"\n",
    "}\n",
    "\n",
    "container = {\n",
    "    \"Image\": ecr_image_uri,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "    \"Environment\": env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=container,\n",
    ")\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "#print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker kill 8af518fd8b56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def encode_image(image):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffer.getvalue())\n",
    "    return img_str\n",
    "\n",
    "\n",
    "# def decode_image(img):\n",
    "#     img = img.encode(\"utf8\") if type(img) == \"bytes\" else img\n",
    "#     buff = BytesIO(base64.b64decode(img))\n",
    "#     image = Image.open(buff)\n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://media.newyorker.com/cartoons/63dc6847be24a6a76d90eb99/master/w_1160,c_limit/230213_a26611_838.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')  \n",
    "display(image.resize((596, 437)))\n",
    "input_image = encode_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_endpoint(endpoint_name, payload):\n",
    "    import json\n",
    "    \n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Accept=\"application/json\",\n",
    "        ContentType=\"application/x-image\",\n",
    "        Body=payload\n",
    "    )\n",
    "    data = response[\"Body\"].read()\n",
    "    output = json.loads(data)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def invoke_endpoint_json(endpoint_name, payload, target_model=None):\n",
    "    import json\n",
    "    \n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Accept=\"application/json\",\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    data = response[\"Body\"].read()\n",
    "    output = json.loads(data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = invoke_endpoint(endpoint_name, input_image)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_value = {'input_image' : input_image.decode(\"utf-8\")}\n",
    "res = invoke_endpoint_json(endpoint_name, input_value)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_endpoint(client, endpoint_name):\n",
    "    response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    EndpointConfigName = response['EndpointConfigName']\n",
    "    \n",
    "    response = client.describe_endpoint_config(EndpointConfigName=EndpointConfigName)\n",
    "    model_name = response['ProductionVariants'][0]['ModelName']\n",
    "    \n",
    "    client.delete_model(ModelName=model_name)    \n",
    "    client.delete_endpoint_config(EndpointConfigName=EndpointConfigName) \n",
    "    client.delete_endpoint(EndpointName=endpoint_name)\n",
    "   \n",
    "    print(f'--- Deleted model: {model_name}')\n",
    "    print(f'--- Deleted endpoint_config: {EndpointConfigName}')     \n",
    "    print(f'--- Deleted endpoint: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delete_endpoint(sm_client, endpoint_name)\n",
    "!sudo rm -rf /tmp/tmp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Endpoint 에서 확인 (원격에서 호스팅)\n",
    "> **⚠️ 주의** : 테스트 후 **반드시** 인스턴스 삭제가 필요합니다. 콘솔에서 SageMakerAI - Inference 에 SageMaker Endpoint가 삭제되었는지 확인해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set to True to enable SageMaker to run locally\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    from sagemaker.local import LocalSession\n",
    "    instance_type = \"local_gpu\"\n",
    "    sm_session = LocalSession()\n",
    "    sm_session.config = {'local': {'local_code': True}}\n",
    "    sm_client = sagemaker.local.LocalSagemakerClient()\n",
    "    smr_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    model_data=f\"file://{Path.cwd()}/model/model.tar.gz\"\n",
    "else:\n",
    "    instance_type = \"ml.g5.2xlarge\"\n",
    "    sm_session = sagemaker.Session()\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "    model_data = model_data_url\n",
    "\n",
    "instance_count = 1\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = f\"blip-model-{ts}\"\n",
    "endpoint_config_name = f\"blip-endpoint-config-{ts}\"\n",
    "endpoint_name = f\"blip-endpoint-{ts}\"\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_endpoint(endpoint_name, payload):\n",
    "    import json\n",
    "    \n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Accept=\"application/json\",\n",
    "        ContentType=\"application/x-image\",\n",
    "        Body=payload\n",
    "    )\n",
    "    data = response[\"Body\"].read()\n",
    "    output = json.loads(data)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def invoke_endpoint_json(endpoint_name, payload, target_model=None):\n",
    "    import json\n",
    "    \n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Accept=\"application/json\",\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    data = response[\"Body\"].read()\n",
    "    output = json.loads(data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    \"SAGEMAKER_CONTAINER_LOG_LEVEL\" : \"20\",\n",
    "    \"SAGEMAKER_PROGRAM\" : \"inference.py\",\n",
    "    \"SAGEMAKER_REGION\" : \"us-west-2\",\n",
    "}\n",
    "\n",
    "# model_data_url = f\"s3://{bucket}/{prefix}/\"  # s3 location where models are stored\n",
    "\n",
    "container = {\n",
    "    \"Image\": ecr_image_uri,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "    \"Environment\": env\n",
    "}\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def make_console_link(region, endpoint_name, task='[SageMaker LLM Serving]'):\n",
    "    endpoint_link = f'<b> {task} <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">Check Endpoint Status</a></b>'   \n",
    "    return endpoint_link\n",
    "\n",
    "endpoint_link = make_console_link(region, endpoint_name)\n",
    "display(HTML(endpoint_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(30)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Accept=\"application/json\",\n",
    "    ContentType=\"application/x-image\",\n",
    "    Body=input_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time\n",
    "res=invoke_endpoint(endpoint_name, input_image)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time\n",
    "input_value = {'input_image' : input_image.decode(\"utf-8\")}\n",
    "res = invoke_endpoint_json(endpoint_name, input_value)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_endpoint(client, endpoint_name):\n",
    "    response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    EndpointConfigName = response['EndpointConfigName']\n",
    "    \n",
    "    response = client.describe_endpoint_config(EndpointConfigName=EndpointConfigName)\n",
    "    model_name = response['ProductionVariants'][0]['ModelName']\n",
    "    \n",
    "    client.delete_model(ModelName=model_name)    \n",
    "    client.delete_endpoint_config(EndpointConfigName=EndpointConfigName) \n",
    "    client.delete_endpoint(EndpointName=endpoint_name)\n",
    "   \n",
    "    print(f'--- Deleted model: {model_name}')\n",
    "    print(f'--- Deleted endpoint_config: {EndpointConfigName}')     \n",
    "    print(f'--- Deleted endpoint: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delete_endpoint(sm_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 4**] ML 모델을 모델 패키지로 패키징\n",
    "---\n",
    "이 **step**에서는 아티팩트(ECR 이미지 및 학습된 모델 아티팩트)를 ModelPackage로 패키징하는 방법을 살펴봅니다. 이 작업을 완료하면 AWS 마켓플레이스에서 제품을 사전 학습된 모델로 등록할 수 있습니다.\n",
    "\n",
    "**Note:** 모델을 여러 하드웨어 유형(CPU/GPU/Inferentia)에 배포할 수 있는 경우, 일반적으로 사용되는 컨테이너 이미지가 각각 다르기 때문에 각각에 대해 모델패키지를 생성하고 MP 목록에 다른 버전으로 추가해야 합니다.  \n",
    "\n",
    "### 모델 패키지 사전 준비\n",
    "모델 패키지는 추론에 필요한 모든 요소를 패키지로 묶은 모델 아티팩트에 대한 재사용 가능한 추상화 형태입니다. 이는 모델 데이터 위치(선택 사항)와 함께 사용할 추론 이미지를 정의하는 추론 사양으로 구성됩니다. ModelPackage는 AWS 마켓플레이스에 판매자로 등록할 AWS 계정에서 생성해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix='blip-large/model_data_customers'\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "account= boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client(\"s3\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = f's3://{bucket}/{prefix}/model.tar.gz'\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithm_name='js-on-boarding-customer'\n",
    "image_tag='blip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecr_image_uri=f\"{account}.dkr.ecr.{region}.amazonaws.com/{algorithm_name}:{image_tag}\"\n",
    "ecr_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# <<YourSupportedContentTypes>>\n",
    "supported_content_types = [\"application/x-image\", \"application/json\"] #[\"text/csv\", \"application/json\", \"application/json\", \"application/jsonlines\"]\n",
    "\n",
    "# <<YourSupportedResponseMIMETypes>>\n",
    "supported_response_MIME_types = [ \n",
    "    \"application/json\",\n",
    "    # \"text/csv\",\n",
    "    # \"application/jsonlines\",\n",
    "]\n",
    "\n",
    "supported_realtime_inference_instance_types = [\"ml.g5.2xlarge\"]\n",
    "supported_batch_transform_instance_types = [\"ml.g5.xlarge\"] #  Don't use batch transform. And, the Batch Transform validation step is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 패키지 생성\n",
    "모델 패키지 생성 프로세스에서는 다음을 지정해야 합니다:\n",
    "  1. 도커 이미지\n",
    "  2. 모델 아티팩트\n",
    "    - tar.gz 형태로 압축된 모델 아티팩트가 제공되어야 합니다.\n",
    "        \n",
    "판매자(및 구매자)에게 Amazon SageMaker에서 제품이 작동한다는 확신을 주기 위해, AWS Marketplace에 제품을 리스팅하기 전에 SageMaker는 기본적인 유효성 검사를 위와 같이 진행하였습니다. 이 유효성 검사 프로세스가 성공해야만 제품을 AWS Marketplace에 리스팅할 수 있습니다. 이 유효성 검사 프로세스는 사용자가 제공한 유효성 검사 프로필과 샘플 데이터를 사용하여 모델을 사용하여 계정에서 변환 작업을 생성하여 추론 이미지가 SageMaker에서 작동하는지 확인합니다.\n",
    "\n",
    "다음으로, ML 모델에 적합한 인스턴스 크기를 식별해야 하며, ML 모델 위에서 성능 테스트를 실행하여 이를 확인할 수 있습니다.\n",
    "\n",
    "**Note:** 모델 튜닝 외에도 인스턴스 유형을 식별할 때 모델의 요구 사항을 고려해야 합니다.  모델이 GPU 리소스를 사용하지 않는 경우 GPU 인스턴스 유형을 포함하지 마세요. 마찬가지로 모델이 GPU 리소스를 사용하지만 단일 GPU만 사용할 수 있는 경우, 여러 개의 GPU가 있는 인스턴스 유형을 포함하지 마세요. 성능상의 이점은 없이 사용자의 인프라 요금만 증가시킬 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트용 샘플이미지 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def encode_image(image):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffer.getvalue())\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://media.newyorker.com/cartoons/63dc6847be24a6a76d90eb99/master/w_1160,c_limit/230213_a26611_838.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')  \n",
    "display(image.resize((596, 437)))\n",
    "input_image = encode_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'input_image' : input_image.decode(\"utf-8\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "s3_client = sagemaker_session.boto_session.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_line = json.dumps(payload)\n",
    "with open(\"input.jsonl\", \"w\") as f:\n",
    "    f.write(json_line)\n",
    "s3_client.put_object(Bucket=bucket, Key=\"validation-input-json/input.jsonl\", Body=json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_file_name = \"input.jsonl\"\n",
    "validation_input_path = f\"s3://{bucket}/validation-input-json/\"\n",
    "validation_output_path = f\"s3://{bucket}/validation-output-jsonl/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "model_name = \"marketplace-model-test-1\" #\"<<YourModelName>>\"\n",
    "model_description = \"marketplace-model-test\" #\"<<YourModelDescription>>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package = sagemaker_session.sagemaker_client.create_model_package(\n",
    "    ModelPackageName=model_name,\n",
    "    ModelPackageDescription=model_description,\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"Image\": ecr_image_uri,\n",
    "                \"ModelDataUrl\": model_data\n",
    "            }\n",
    "        ],\n",
    "        \"SupportedTransformInstanceTypes\": supported_batch_transform_instance_types,\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": supported_realtime_inference_instance_types,\n",
    "        \"SupportedContentTypes\": supported_content_types,\n",
    "        \"SupportedResponseMIMETypes\": supported_response_MIME_types,\n",
    "    },\n",
    "    CertifyForMarketplace=True,  # Make sure to set this to True\n",
    "   ValidationSpecification={\n",
    "        'ValidationRole': role,\n",
    "        'ValidationProfiles': [\n",
    "            {\n",
    "                'ProfileName': \"validation\",\n",
    "                'TransformJobDefinition': {\n",
    "                    'MaxConcurrentTransforms': 1,\n",
    "                    'MaxPayloadInMB': 64,\n",
    "                    'BatchStrategy': 'SingleRecord',\n",
    "                    'TransformInput': {\n",
    "                        'DataSource': {\n",
    "                            'S3DataSource': {\n",
    "                                'S3DataType': 'S3Prefix',\n",
    "                                'S3Uri': f'{validation_input_path}input.jsonl'\n",
    "                            }\n",
    "                        },\n",
    "                        'ContentType': 'application/json',\n",
    "                        'CompressionType': 'None',\n",
    "                        'SplitType': 'None'\n",
    "                    },\n",
    "                    'TransformOutput': {\n",
    "                        'S3OutputPath': f'{validation_output_path}output.json',\n",
    "                        'Accept': 'application/json',\n",
    "                        'AssembleWith': 'None',\n",
    "                    },\n",
    "                    'TransformResources': {\n",
    "                        'InstanceType': 'ml.g5.xlarge',\n",
    "                        'InstanceCount': 1,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.wait_for_model_package(model_package_name=model_name) # If failure occurs navigate to SageMaker Console > My marketplace model packages > select the failed ModelPackage for details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음을 실행하기 전에, [Model Packages console from Amazon SageMaker](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/model-packages/my-resources)을 열어서 모델 생성의 성공했는지를 확인해야 합니다.\n",
    "모델을 선택하고 **Validation** 탭을 열어서 validation 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 5**] Amazon SageMaker에 배포하여 ML 모델 패키지 검증\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 패키지에서 모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package['ModelPackageArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "model = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package[\"ModelPackageArn\"],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SageMaker 모델을 Endpoint로 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=supported_realtime_inference_instance_types[0],\n",
    "    endpoint_name=model_name,\n",
    ")\n",
    "model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### boto3로 예시 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make use of your own example input data to test the Endpoint\n",
    "#input_json = '{\"text\": \"sample\"}'\n",
    "\n",
    "payload = {'input_image' : input_image.decode(\"utf-8\")}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=model.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    Body=json.dumps(payload),\n",
    ")\n",
    "\n",
    "json.load(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS CLI로 예시 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $model.endpoint_name \\\n",
    "    --body fileb://$validation_file_name \\\n",
    "    --content-type application/json \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    out.out\n",
    "    \n",
    "    \n",
    "# Print inference\n",
    "!head out.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성된 endpoint configuration 과 endpoint 정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model.endpoint_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델은 필수가 아니므로 삭제해도 됩니다. \n",
    "- 배포 가능한 모델을 삭제한다는 점에 유의하세요. \n",
    "- 모델 패키지는 삭제하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AWS 마켓플레이스에 모델을 게시하려면 모델 패키지 ARN을 지정해야 합니다. 다음 모델 패키지 ARN을 복사합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package[\"ModelPackageArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## [**Step 6**] AWS Marketplace에 ML 모델 등록\n",
    "---\n",
    "\n",
    "1.  모델 파트너는 AWS 마켓플레이스에서 [public profile](https://docs.aws.amazon.com/marketplace/latest/userguide/seller-registration-process.html#seller-public-profile)을 생성하고 seller로 등록합니다.\n",
    "마켓플레이스의 상품은 무료 상품으로 등록되므로 세금 정보를 제공할 필요가 없습니다.\n",
    "\n",
    "2. 세이지메이커 콘솔의 [Model Packages](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/model-packages/my-resources) 섹션에서 이 노트북에서 생성한 엔티티를 찾을 수 있습니다. 성공적으로 생성되고 유효성이 검사되었다면 해당 엔티티를 선택하고 **Publish new ML Marketplace listing**를 선택할 수 있을 것입니다.\n",
    "\n",
    "<img src=\"images/publish-to-marketplace-action.png\"/>\n",
    "\n",
    "리스팅을 작성할 수 있는 [AWS Marketplace Management portal](https://aws.amazon.com/marketplace/management/ml-products/)로 리디렉션됩니다.\n",
    "\n",
    "<img src=\"images/listing.png\"/>\n",
    "\n",
    "1. 모델이 여러 하드웨어 유형을 대상으로 하는 경우 각 ModelPackage를 별도의 버전으로 목록에 추가하는 것을 잊지 마세요.\n",
    "2. 추가를 클릭하고 모델 정보를 입력합니다. Product visibility을 'Public'로 설정해야 합니다.\n",
    "\n",
    "<img src=\"images/public.png\"/>\n",
    "\n",
    "3. 테스트를 진행할 account 에 대해 모델 접근을 위한 Allowlist에 추가합니다. 예) account `171503325295`, `572320329544` and `559110549532` for access to the model. \n",
    "For region support select: `us-east-1, us-west-2, eu-west-1, eu-central-1, eu-west-2, ap-northeast-1, ap-south-1, ca-central-1, us-east-2, ap-northeast-2`\n",
    "<img src=\"images/allowlist-accs.png\"/>\n",
    "\n",
    "4. Pricing and terms 하에 pricing 모델을 설정합니다.\n",
    "**Inference based pricing (custom metering) at $0**\n",
    "\n",
    "(선택 사항) 컨테이너가 아래를 구현하지 않은 경우 이를 확인하고 다음을 진행하세요. \n",
    "\n",
    "```\n",
    "I confirm that my model package supports the response header for custom metering. Example response header: X-Amzn-Inference-Metering:\n",
    "{\"Dimension\": \"inference.count\", \"ConsumedUnits\": 3}\n",
    "I understand that in absence of this header, default metering will be used instead.\n",
    "```\n",
    "\n",
    "<img src=\"images/inference-based-pricing.png\"/>\n",
    "\n",
    "5. Listing 상태는 다음과 같이 표시되어야 합니다:\n",
    "**Do not click Sign off and publish**\n",
    "\n",
    "<img src=\"images/status-1.png\"/>\n",
    "\n",
    "6. Vissibility status of the listing should be `Limited`.\n",
    "\n",
    "<img src=\"images/status-2.png\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "* [Publishing your product in AWS Marketplace](https://docs.aws.amazon.com/marketplace/latest/userguide/ml-publishing-your-product-in-aws-marketplace.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
